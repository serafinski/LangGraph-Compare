.. LangGraph Log Parser documentation master file, created by
   sphinx-quickstart on Sat Nov 16 00:19:00 2024.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

LangGraph Log Parser documentation
##################################

.. contents:: Table of Contents

Purpose
*******
This Python package facilitates the parsing of run logs generated by `LangGraph <https://langchain-ai.github.io/langgraph/>`_. During execution, logs are stored in an SQLite database in an encoded format `(using msgpack)`. These logs are then decoded and exported to a :code:`json` format. Subsequently, the :code:`json` files are transformed into :code:`csv` files for further analysis.

Once in :code:`csv` format, the data can be analyzed using methods from the `pm4py <https://processintelligence.solutions/static/api/2.7.11/index.html>`_ library. These methods calculate specific statistics related to the multi-agent infrastructure's performance and enable visualizations of the process behavior and execution flow.

This pipeline provides a streamlined approach for extracting, transforming, and analyzing logs, offering valuable insights into multi-agent systems.

Usage
*****

Installation
============

This `package <https://pypi.org/project/langgraph_log_parser/>`_ requires Python 3.10 or higher.

To create virtual environment (using conda), use the following commands:

.. code-block:: console

   conda create -n langgraph_log_parser python=3.10
   conda activate langgraph_log_parser
   pip install langgraph_log_parser

Getting started
===============
For basic usage example, refer to: :ref:`getting_started`

Advanced Examples
=================
For advanced use cases, refer to: :ref:`advanced_examples`


Basic example
*************
This example is based on the `Building a Basic Chatbot <https://langchain-ai.github.io/langgraph/tutorials/introduction/#part-1-build-a-basic-chatbot>`_ from LangGraph documentation.

For detailed explanation of the code, see: :ref:`getting_started` and :ref:`advanced_examples`.

.. code-block:: python

   import sqlite3

   from dotenv import load_dotenv
   from typing import Annotated

   from langgraph.checkpoint.sqlite import SqliteSaver
   from typing_extensions import TypedDict
   from langchain_openai import ChatOpenAI
   from langgraph.graph import StateGraph, START, END
   from langgraph.graph.message import add_messages

   from langgraph_log_parser import *

   exp = create_experiment("main")

   load_dotenv()

   conn = sqlite3.connect(exp.database, check_same_thread=False)
   memory = SqliteSaver(conn)

   class State(TypedDict):
       messages: Annotated[list, add_messages]

   graph_builder = StateGraph(State)

   llm = ChatOpenAI(model="gpt-4o-mini")

   def chatbot(state: State):
       return {"messages": [llm.invoke(state["messages"])]}

   graph_builder.add_node("chatbot_node", chatbot)

   graph_builder.add_edge(START, "chatbot_node")
   graph_builder.add_edge("chatbot_node", END)

   graph = graph_builder.compile(checkpointer=memory)

   run_multiple_iterations(graph, 1, 5, {"messages": [("user", "Tell me a joke")]})

   export_sqlite_to_jsons(exp.database, exp.json_dir)

   graph_config = GraphConfig(
       nodes=["chatbot_node"]
   )

   export_jsons_to_csv(exp.json_dir, exp.get_csv_path(), graph_config)

   print()
   event_log = load_event_log(exp.get_csv_path())
   print_analysis(event_log)

   write_report(event_log, exp.reports_all_dir)

   generate_visualizations(event_log, graph, exp.img_dir)

Modules
*******
To see exact uses of every class, method, module etc. see:

.. toctree::
   :maxdepth: 1

   modules

Indices and tables
******************

* :ref:`genindex`
* :ref:`modindex`