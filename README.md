# LangGraph Log Parser
[![wakatime](https://wakatime.com/badge/user/c88d1b82-ebdd-4842-ad45-93f471842103/project/b6d31f0d-340f-42d5-aa2d-bf3e2e6a0370.svg)](https://wakatime.com/badge/user/c88d1b82-ebdd-4842-ad45-93f471842103/project/b6d31f0d-340f-42d5-aa2d-bf3e2e6a0370)

# Documentation
Documentation is available at: https://serafinski.github.io/LangGraph-Log-Parser/

# Purpose
This Python package facilitates the parsing of run logs generated by [LangGraph](https://langchain-ai.github.io/langgraph/). During execution, logs are stored in an SQLite database in an encoded format _(using msgpack)_. These logs are then decoded and exported to a `json` format. Subsequently, the `json` files are transformed into `csv` files for further analysis.

Once in `csv` format, the data can be analyzed using methods from the [py4pm](https://processintelligence.solutions/static/api/2.7.11/index.html) library. These methods calculate specific statistics related to the multi-agent infrastructure's performance and enable visualizations of the process behavior and execution flow.

This pipeline provides a streamlined approach for extracting, transforming, and analyzing logs, offering valuable insights into multi-agent systems.

# Installation
This package requires Python 3.10 or higher.

To create virtual environment (using conda), use the following commands:
```dotenv
conda create -n langgraph_log_parser python=3.10
conda activate langgraph_log_parser
pip install langgraph_log_parser
```
# Basic Example
This example is based on the [Building a Basic Chatbot](https://langchain-ai.github.io/langgraph/tutorials/introduction/#part-1-build-a-basic-chatbot) from LangGraph documentation.
```python
import sqlite3

from dotenv import load_dotenv
from typing import Annotated

from langgraph.checkpoint.sqlite import SqliteSaver
from typing_extensions import TypedDict
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

from langgraph_log_parser import *

exp = create_experiment("main")

load_dotenv()

conn = sqlite3.connect(exp.database, check_same_thread=False)
memory = SqliteSaver(conn)

class State(TypedDict):
    messages: Annotated[list, add_messages]

graph_builder = StateGraph(State)

llm = ChatOpenAI(model="gpt-4o-mini")

def chatbot(state: State):
    return {"messages": [llm.invoke(state["messages"])]}

graph_builder.add_node("chatbot_node", chatbot)

graph_builder.add_edge(START, "chatbot_node")
graph_builder.add_edge("chatbot_node", END)

graph = graph_builder.compile(checkpointer=memory)

run_multiple_iterations(graph, 1, 5, {"messages": [("user", "Tell me a joke")]})

export_sqlite_to_jsons(exp.database, exp.json_dir)

graph_config = GraphConfig(
    nodes=["chatbot_node"]
)

export_jsons_to_csv(exp.json_dir, exp.get_csv_path(), graph_config)

print()
event_log = load_event_log(exp.get_csv_path())
print_analysis(event_log)

write_report(event_log, exp.reports_all_dir)

generate_visualizations(event_log, graph, exp.img_dir)
```